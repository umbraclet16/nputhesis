% 第六章 总结与展望

\chapter{总结与展望}

\section{论文总结}
旋翼无人机由于其灵活的机动性与较低的成本，在生活中得到了越来越广泛的应用。对环境中各种目标的感知与交互能力是提高旋翼无人机的任务能力、保障飞行安全的重要因素。本文以基于双目立体视觉的目标检测与定位算法为研究内容，设计并实现了旋翼无人机目标检测定位系统。本文主要完成的工作如下：

1、建立了摄像机模型，并介绍了双目立体视觉理论。首先根据摄像机成像过程定义了相关坐标系，给出了坐标变换关系，分别建立了摄像机的线性和非线性模型。介绍了双目立体视觉原理中的三角测量、对极几何等理论，推导并应用 Bouguet算法和张正友标定法完成了ZED双目相机的标定实验，获得了良好的标定精度。 

2、提出了基于YOLO的改进目标检测算法。在具体分析了YOLO目标检测算法的策略与过程后，针对模型代价函数的不合理处和算法召回率较低的问题，对网络模型的代价函数和网络结构进行了修改。在TensorFlow平台上搭建了网络模型，使用PASCAL VOC数据集进行了训练，并给出了多种目标物体的实验结果。算法在GPU上的运行速度在30Hz以上，能够满足实时应用的要求。 

3、建立了DispNetC立体匹配网络模型。介绍了端到端的立体匹配模型DispNet及加入相关层的DispNetC网络结构，使用TensorFlow搭建了DispNetC网络，分别在FlyingThings3D和KITTI 2015数据集上进行了训练和微调，给出了两个数据集上的测试结果，并与SGM、SPS-St等算法进行了对比，分析了算法的优缺点。测试结果显示DispNetC具有较高的匹配精度，而运行时间仅为0.06秒，远快于大多数的立体匹配算法。最后分析了训练集大小对网络匹配精度的影响，比较结果说明增大训练数据量有利于提高匹配精度。 

4、搭建了旋翼无人机目标检测定位系统。首先介绍了硬件系统的组成，然后提出了融合目标检测与立体匹配结果进行目标定位的方案，利用GrabCut算法提取目标轮廓并确定目标中心，结合立体匹配结果，应用三角测量原理完成摄像机坐标系下的目标定位，再通过坐标变换实现机体系和导航系下的目标定位。最后给出了实验结果，并进行了误差分析。 

\vfill

\section{工作展望}
本文完成了基于双目立体视觉的目标检测与定位算法框架，并搭建了旋翼无人机目标检测定位系统。但由于时间、个人知识水平和实验条件等因素的限制，在算法研究与应用实现等方面仍存在需要改进和完善的地方。

1、目标检测方面，训练使用的PASCAL VOC数据集包含20种物体，可根据具体的应用需求对物体类别进行调整。其次，由于无人机的视角与日常的图片有一定区别，因此可考虑收集飞行中拍摄的图像并制作数据集，用来训练或finetune目标检测网络模型，以获得更好的检测效果，并增加对某些类别的支持（如树、电线杆等）。另外，算法存在的某些缺陷仍待解决。原算法作者已提出了一些提高召回率和检测框定位精度的手段，可进行研究。
%改进算法的定量分析工作和与其他算法的比较尚未完成

2、立体匹配方面，由于训练使用的数据集对应双目相机的基线长度远比实际应用时ZED双目相机的基线长，也就是说训练图像的平均视差大于实际应用场景的平均视差，因此算法迁移时精度会有所下降。双目相机的基线长度是限制其测距距离的重要因素，因此使用基线更长的相机是比较好的选择。另外，目标定位前使用图像分割算法确定目标中心的时间代价较大，可尝试在视差图上使用聚类方法提取目标轮廓。

3、旋翼无人机目标检测定位系统中有许多工作可以开展。相机可使用云台来安装在无人机上，以获得更灵活的视角；安装图传设备将目标图像实时回传，获得可视的目标定位结果；加入数据链路的反向数据流，即由地面站发送指令，实时调整目标检测的物体类别、阈值等参数。视觉信息可与无人机的控制、导航系统进行交互，以完成具体的任务。


% YOLO根据所需检测的类别进行简化；引入YOLO v2的改进；YOLO测试结果的定量分析和与其他算法的比较；
% detection和stereo correspondence针对特定应用场景的专门数据集的训练；数据集类别的增加（树、电线杆）；
% 旋翼无人机系统面向应用的功能开发。

% dispnet可以引入图像边缘的信息？

% disparity和rgb分割结果怎么融合？
%换更大基线的相机？增加云台。
% 地面站部分的开发。图像显示，目标位置显示。视觉与控制的交互。
%数据链反向交互操作：地面站传输命令给飞控，飞控通过串口发给TX2，TX2调整检测的目标或程序相关设置。