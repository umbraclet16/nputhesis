% 第一章 综述

\chapter{综述}

\section{研究背景及意义}
% 袁峻、朱玮、苏东、周士超。（刘天奇、邵慧、金兆飞）

% 无人机是什么？
无人机（Unmanned Aerial Vehicle）是一类利用无线电遥控设备或机载飞行控制系统代替飞行员进行操控的不载人的飞行器。相较有人驾驶飞机，无人机体积更小、成本更低，反应快速，机动能力和环境适应能力强，因而受到了广泛的关注和研究。从上个世纪九十年代起，微电子技术、材料技术、通信技术、传感器技术等发展迅速，很多限制无人机应用的技术难题得到了解决，无人机的性能逐渐提升，在现实生活中得到了越来越多的应用。

% 无人机有什么用？
无人机的种类繁多，按照产生升力的方式来划分，大致可分为固定翼无人机、旋翼无人机和扑翼无人机等三种类型。固定翼无人机气动效率较高，负载能力强，适合于长距离飞行，但因起降需要一定的场地条件，因此应用受到了一定的限制。而旋翼无人机体积小、重量轻，结构简单，价格相对低廉，具备垂直起降和空中悬停的能力，飞行速度低、机动性好，能够在一些狭小、复杂的空间飞行，可以执行很多固定翼无法完成的任务，近年来得到了越来越多的关注。

在军事领域，无人机多被应用于搜寻侦察、战场局势监控、电子对抗、毁伤评估、信号中继等任务\cite{刘天奇2015}\cite{朱玮2014}；而在民用方面，旋翼无人机已应用于非常多的场景和行业，包括但不限于航空摄影、灾情监视与评估、治安监控、空气检测、资源勘探、植被保护、电力巡线等。我国每年发生的各种自然灾害以及社会治安事件会导致逾百万的人员伤亡和数十亿的经济损失\cite{陈丽娟2013}，这些突发事件难以预见且破坏性大。旋翼无人机可以在处理突然事件时发挥巨大作用：实现快速响应，迅速完成态势评估，有利于相关人员采取正确有效的措施；能够在通信设施受到破坏的区域进行通信中继；参与具体的救援行动，如药物等救援物资。在电力巡线领域，旋翼无人机沿电网进行自主巡航，拍摄影像传送回地面站，提高了巡检的效率，也避免了现场巡检可能出现的安全事故\cite{周士超2016}。


%微型旋翼飞行器具有悬停、低速巡航的特点，可以作为摄像机的理想载体，有效扩大摄像机的视野。搭载了摄像机等视觉传感器的微型无人机可以对地面目标进行空中监视和跟踪飞行，有效地完成交通监控、反恐防暴、抗灾救险、海上搜救等任务。

% 引出视觉
% 基于视觉的无人机目标检测与定位
% 《无人机图像目标跟踪与定位》，袁峻，p8.
随着图像处理等相关技术的快速发展以及硬件设备运算能力的大幅提高，计算机视觉技术在无人机领域得到了越来越多的应用\cite{袁峻2017}。得益于图像包含的大量信息，无人机能够更好地感知周边环境，从而提高飞行的安全性和成功执行任务的几率。基于视觉的目标检测与定位技术已经成为无人机进行任务环境感知、任务目标交互的重要手段。因此，将目标检测、定位等先进视觉技术应用于无人机领域，使其向自主化、智能化的方向发展，具有重要的研究意义。

% 无人机目标检测与定位有什么用？
%更加精细的任务：中航工业创新大奖赛、IMAV之类的。
近年来，很多科研机构和无人机行业组织举办了一些竞赛活动来促进旋翼无人机结合视觉技术的相关研究与应用。2016年在北京举办的国际微小型无人飞行器竞赛（International Micro Air Vehicle）设置了“模拟海上搜救”的比赛主题，以海上钻井平台起火、平台操作人员落水为背景，要求旋翼无人机自主完成模拟灭火、水上勘测及救援任务等科目；2017年第四届国际无人飞行器创新大奖赛以“精准农业”为主题，要求旋翼无人机自主识别模拟的农作物灾害并进行施药。这些任务贴近现实应用场景，对目标检测与定位技术提出了很高的要求；比赛结果体现了目标检测与定位技术在具体应用中能够发挥巨大作用，而当前的技术水平仍不甚成熟，因此需要开展更多相关的研究工作。

% 目标定位一般有什么方法，然后引到双目立体视觉。
% 《基于视觉的目标定位技术的研究进展》[J]，赵霞，2016.
利用视觉传感器进行目标定位相较利用雷达、激光、红外等传统的目标定位技术具有应用条件宽松、抗干扰能力强、成本较低且信息量丰富的优势。根据使用视觉传感器的数量，视觉定位方法可分为基于单目、双目和全景的视觉定位\cite{赵霞2016}。基于单目视觉的定位计算量小，但定位精度低；基于全方位视觉的定位计算过于复杂，难以达到实时性；因而基于双目视觉的目标定位是该领域的研究热点。

% 苏东p11
双目立体视觉技术模拟了人类的双眼感知三维空间的机制，经过图像采集、立体校正、立体匹配等步骤得到视差图，通过三维空间与二维图像平面的映射关系来计算场景中物体的实际深度，从而重建出三维场景，也就实现了对场景中目标的定位\cite{苏东2014}。利用双目视觉技术进行目标检测与定位，具有系统结构简单、成本低、精度合适、不易被发现等优势，因而非常适合应用于旋翼无人机系统中。

% 刘天奇p11。无人机视觉导航系统与一般视觉处理系统的区别。

% 目标定位的研究概况？
%无人机结合视觉技术的研究现状？朱玮，ch1.2.2，p17

%------------------------------------------------------------------------------------
\section{目标检测的研究概况}
% 杨眷玉、郑嘉祺
目标检测或物体检测是指从一张图片或视频的多帧图像中检测出某种或多种目标物体，并定位出目标在图像中的位置，一般使用矩形框来给出直观的检测结果。目标检测是计算机视觉领域的一个重要研究方向，并且具有广泛的应用需求，目前已应用于智能视频监控、视觉导航、身份识别、工业自动化等领域，因而相关研究成果也较为丰富。

% 《基于视觉的目标检测与跟踪综述》[J]，尹宏鹏。
目标检测可分为基于背景建模和基于目标建模两大类\cite{尹宏鹏2016}。
基于背景建模的检测方法通常应用于检测视频中的运动目标，通过建立背景模型后将当前帧与背景模型对比来分离出运动前景。其实现较为简单、运算速度快，但适用范围有限，一般只能用在摄像机固定的场景，且容易受到光照变化等因素干扰。
本文关注的是应用范围更为广泛的基于目标建模的检测算法。其包括离线训练和在线检测两个阶段，训练阶段从训练数据中抽取出目标的特征表达并建立目标模型，之后训练分类器用于目标检测。在线检测基于相同的特征提取方式建立图像的模型，然后使用训练好的分类器来判断图像中是否存在所检测的目标。可见，目标检测的基本框架即“特征表达+分类器”。下面分别介绍传统的目标检测方法和基于深度学习的目标检测方法。

\subsection{传统目标检测方法}
% 特征提取。尹宏鹏，p5。（杨眷玉，p11）
特征表达，或称为特征提取，是从图像像素中抽取出可用于区分图像内容的信息的过程，也是在底层信息与高层语义之间建立联系的至关重要的一步。传统目标检测算法使用的是基于人工设计的特征，其利用人总结的先验知识，计算较为简单，实现也比较容易，但由于完全依赖人类的经验，难以刻画出图像的本质特征。

人工设计的特征按不同标准可进行不同的分类。\cite{尹宏鹏2016}将其分为梯度特征、模式特征、颜色特征以及形状特征等四个类别。%；而\cite{郭明玮2014}将其分为整体特征、局部特征和上下文特征等三类。
% 整体特征，局部特征，上下文特征。 《基于支持向量机的目标检测算法综述》，郭明玮
梯度特征，顾名思义，使用图像中各位置的梯度强度、方向等信息来对图中物体进行描述。其中最著名的是Lowe于2004年提出的SIFT特征\cite{Lowe2004Distinctive}，即尺度不变特征变换。该特征能较好地适应图像的尺度和旋转变换，具有较强的鲁棒性。基于其的改进包括PCA-SIFT\cite{Ke2004PCA}、加速鲁棒特征（SURF）\cite{Bay2006SURF}、雏菊花特征（DAISY）\cite{Tola2010DAISY}等。
方向梯度直方图（HOG）\cite{Dalal2005Histograms}是Dalal等人提出的一种应用于行人检测领域的特征，变尺度梯度直方图（v-HOG）\cite{Zhu2006Fast}、GIST\cite{Torralba2006Contextual}、共生梯度直方图（CoHOG）\cite{Watanabe2009Co}等是一些对HOG的改进。
常见的模式特征主要有Gabor滤波器特征\cite{Jain1997Object}、局部二值模式（LBP）\cite{Zhou20103D}、Haar-Like特征\cite{Viola2001Robust}、局部区域描述（Regionlets）\cite{Wang2014Regionlets}等。
形状特征的代表有DPM\cite{felzenszwalb2010object}、形状上下文（Shape context）\cite{belongie2002shape}、kAS\cite{ferrari2008groups}，颜色特征则有颜色SIFT特征\cite{rassem2011object}、颜色属性\cite{van2009learning}等，由于篇幅所限，在此不再详细介绍，具体可参照文献\cite{尹宏鹏2016}。

% 分类器介绍
在利用特征表达完成对图像的描述后，需要使用一个分类器来进行基于特征的分类。使用最广泛的分类器是支持向量机（SVM）\cite{kotsiantis2006machine}。
% SVM优缺点
SVM具有诸多优点\cite{郭明玮2014}，如系统结构简单，分类器的复杂程度只与支持向量的数量有关，而与训练集样本数目无关；能得到全局最优解，从而保证较高的准确率；推广能力强，实用性较广。
引入核方法能够提高SVM的效果，常用的核函数有Sigmoid、RBF、GaussianRBF等\cite{scholkopf2001learning}。
基于SVM的目标检测算法存在的问题主要是检测时间较长，难以满足实时性要求；对大规模训练数据难以应用。
支持向量机是二分类器，检测多种目标需要集成多个分类器得到一个强分类器，常用的方法有Bagging、Boosting及随机森林等。Softmax是一种适用于多分类的分类器，其效果优于SVM，近年来得到了越来越多的应用。

%滑动窗口。郑嘉祺
传统检测方法确定目标位置一般采用滑动窗口的方式，以不同的尺度和长宽比对整张图像进行遍历，从而检测出大小和长宽比例都不确定的目标。这种穷举的策略虽然能够达到检测目的，但复杂度过高，会产生很多无用的窗口，导致算法效率低下。

\subsection{基于深度学习的目标检测方法}
% DPM, R-CNN, SPPNet, Fast R-CNN, Faster R-CNN, YOLO, (MobileNet，OverFeat，SSD?)
% 传统方法的局限。黄咨，p13.
传统方法中人工提取的特征具有很多局限性，如SIFT特征要求图像包含丰富的纹理特征，否则易造成错误匹配；HOG难以处理局部遮挡的目标。另外，传统方法将特征提取和分类训练割裂开来，如果提取的特征不理想，则分类训练就无法利用很多有用的分类信息。这些缺点导致传统检测方法无法获得很好的检测效果。
%传统目标检测算法中使用的人工特征提取方法和分类器都存在着一些局限性，因而检测效果一直无法达到很好的水平。
而近年来涌现出很多基于深度学习的目标检测算法，将该领域的研究带入了一个新的阶段。

% 郑嘉祺p11.
1、基于区域提名的检测算法

很多基于深度学习的目标检测算法同传统方法一样需要先从图像中选出一些可能包含目标的矩形框，这个步骤称为区域提名（region proposal）。文献\cite{hosang2014good, hosang2016makes, chavali2016object}等综述并比较了该步骤使用的算法。应用较多的包括基于超像素聚合的方法（选择性搜索\cite{uijlings2013selective}、CPMC\cite{carreira2012cpmc}、MCG\cite{arbelaez2014multiscale}）和基于滑动窗口的方法（objectness\cite{alexe2012measuring}、边盒\cite{zitnick2014edge}）。区域提名通常作为独立于检测网络的外部模块。

2014年，目标检测的领军人物Girshick提出了R-CNN框架\cite{girshick2014rich}，将选择性搜索加入CNN模型中以解决滑动窗口的时间复杂度问题。其首先使用选择性搜索来完成区域提名，然后使用CNN进行特征提取，最后通过全连接层完成分类，使用BB盒回归来获得准确的检测框。该方法使目标检测的准确度获得了大幅的提升，但缺点在于计算量大，对于每一个提名的矩形框区域都要进行一次特征提取，在一张图片上的耗时达数十秒。
2015年，He等人提出了SPP-Net\cite{he2014spatial}，引入空间金字塔池化策略，优化了R-CNN的检测流程，使检测速度得到了一定的提升。
Girshick借鉴了SPP-Net中区域提名的思路，并加入多任务损失函数，又提出了Fast R-CNN\cite{girshick2015fast}，先使用卷积网络提取整张图像的特征，再将提名的区域映射到特征图中，并使用RoI最大池化来获得固定尺寸的特征图，最后在特征向量上进行分类。网络中的RoI最大池化层相当于SPP-Net中空间金字塔池化层的一个特例，即只使用了一层金字塔。
Fast R-CNN的检测网络耗时仅为0.3秒，此时基于选择性搜索的区域提名成为了整个算法的瓶颈，其每次产生约2000个提名，耗时近2秒。在这种情况下，Faster R-CNN\cite{ren2015faster}应运而生。Faster R-CNN使用区域提名网络（RPN）代替了基于选择性搜索的区域提名模块，并使RPN和Fast R-CNN共享卷积层提取的特征，从而将运行速度提高到了5fps。


2、基于回归方法的检测算法

R-CNN系列的目标检测算法在经过多次改进后，仍然距离实时检测有一定的差距。这些方法在完成分类后还需要一些后处理操作来对获得较准确的检测框，过程较为复杂，因此运行速度很难得到更大的提升。2016年，Redmon等人提出了YOLO目标检测算法\cite{redmon2016you}。该算法将目标检测任务作为一个回归问题来处理，直接建立图像像素与目标检测框坐标和物体类别概率的回归关系。YOLO的运行速度非常快，基础版本能够达到45fps，而简化的快速版本更是达到了150fps，因而可以用于实时处理视频流。由于在检测时利用整张图像的信息，YOLO不容易将背景区域误检测为目标；但由于不使用候选区域，其检测结果的位置误差要比Faster R-CNN更大。YOLO的检测精度相较之前其他的实时检测算法提升了一倍，非常适合于实时的应用场景。
除YOLO外，OverFeat\cite{sermanet2013overfeat}和SSD\cite{liu2016ssd}也是跳过区域提名步骤直接进行检测框预测的算法。


%------------------------------------------------------------------------------------
\section{立体匹配的研究概况}
% 研究现状，研究目标，研究内容

% ref: GC-Net ch2.
使用立体图像对来计算深度信息的研究已经进行了很多年\cite{Barnard1982}，而立体匹配是双目立体视觉中最重要的部分。Scharstein和Szeliski于2002年发表的一篇综述论文\cite{Scharstein2002}对立体匹配算法进行了分类，将立体匹配分为四个步骤：匹配代价计算(matching cost computation)、代价支持聚合(cost support aggregation)、视差计算和优化(disparity computation and optimization)和视差精炼(disparity refinement)。大部分立体匹配算法都可以归类为这四个步骤的子集。

Scharstein的综述还介绍了Middlebury的第一个数据集和相关的评价指标，并提供了使用结构光测量方法获得的数据集的测量真值(groundtruth)。KITTI数据集\cite{Geiger2012,Menze_2015_CVPR}是一个比Middlebury更大的数据集，其图像是在一辆行驶中的汽车上采集的，真实数据通过激光雷达获得。这些数据集推动了立体匹配算法的发展。
近年来随着深度学习的流行，出现了很多基于卷积神经网络的立体匹配方法。在此我们将不使用深度学习模型的方法归为传统方法，和基于深度学习的方法分别进行介绍。

\subsection{传统立体匹配方法}
% ref: SGM paper ch1.
传统立体匹配方法大致可分为局部方法和全局方法两类。局部方法至少包含匹配代价计算、代价聚合和视差计算三个部分。匹配代价是一种用来衡量潜在匹配区域内像素差异性的手段。常见的匹配代价包括绝对差值、平方差值、截断差值和对采样不敏感的差值\cite{Birchfield1999}等。这些代价对于光照度差异比较敏感，可以采用基于图像梯度的匹配代价进行改善\cite{SGM_3}。为了处理图像间复杂的光照度关系，互信息被引入了计算机视觉领域\cite{Viola1997}，并应用于立体匹配中\cite{SGM_6}。匹配代价聚合将一定范围内的匹配代价联系起来，通常仅仅是在某个固定尺寸的窗口内对所有的匹配代价进行求和\cite{Hirschmüller2002}。也有一些方法根据颜色相似度和距离中心的距离对窗口内各个像素进行加权\cite{SGM_10}。另外一种方式是根据基于相同亮度或颜色进行分割得到的结果来选择代价聚合的区域\cite{Zitnick2004}。视差计算是通过选择最低匹配代价的视差完成的\cite{Hirschmüller2002}，即“赢者通吃”(Winner Takes All)。局部方法计算量小，算法效率高，但对于低纹理、遮挡和视差不连续的区域匹配效果较差。

全局匹配方法一般会跳过代价聚集的步骤，定义一个包含数据项和平滑项的能量函数，将匹配转化为最小化能量函数的优化问题。平滑项的加入有助于获得分段光滑的视差。有些算法还会额外加入惩罚遮挡\cite{SGM_13}、强制左右图一致性\cite{Zitnick2004}的数据项。最小化能量函数的策略有很多，包括图割(Graph Cuts)\cite{SGM_13}，置信传播(Belief Propagation)\cite{SGM_3}，动态规划\cite{VanMeerbergen2002}等。\cite{MRF}和\cite{CRF}分别使用数据集的真实深度图来训练马尔科夫随机场(MRF)和条件随机场(CRF)模型。

全局匹配算法的优点是匹配准确度较高，但其计算量很大，相应的参数设置也比较复杂。半全局匹配(SGM)\cite{Hirschmuller08}是一种对全局算法的有效近似，通过多个方向上的动态规划降低了计算复杂度，既能获得媲美全局算法的的匹配效果，又能保证较高的效率。

\subsection{基于深度学习的立体匹配方法}
% ref: CRL paper, ch2; SsSMNet paper ch2.
传统立体匹配方法对于匹配无纹理区域、反射平面、重复图案、细微结构等表现不佳。很多算法通过池化、基于梯度的正则化\cite{geiger2010efficient, hirschmuller2005accurate}来解决这些问题，但通常需要在平滑表面和检测细节方面进行折中。而深度学习模型已经在物体分类\cite{krizhevsky2012imagenet}、检测\cite{girshick2014rich}和语义分割\cite{badrinarayanan2015segnet}等方面取得了巨大成功，显示出了深度卷积神经网络在理解语义方面的有效性。事实上，近年来深度卷积神经网络也已被成功应用于立体匹配，并大大推动了该领域的发展。基于CNN的匹配方法大致可以分为三类：匹配代价学习、
正则学习(regularity learning)和端到端(End-to-end)的视差学习。

匹配代价学习：使用卷积神经网络获得的图像特征取代人工设计的匹配代价指标。Han等人\cite{Han_2015_CVPR}提出了MatchNet，该模型从成对的图像块中提取特征，然后用一个决策模块来衡量相似度。Zbontar等人\cite{zbontar2016stereo}设计了MC-CNN模型，训练了一个用于匹配的二元分类器。Luo等人\cite{luo2016efficient}提出了Content-CNN用来学习所有视差值的概率分布，这种策略不需要考虑训练样本数量的不平衡。尽管此类数据驱动的相似度指标表现优于传统的手工指标，后处理对于获得理想的匹配结果仍然是必要的。

正则学习：基于视差图通常是分段平滑的事实，一些模型在学习过程中强制加入了平滑约束。Menze等人\cite{Menze_2015_CVPR}应用基于纹理和边缘信息的自适应平滑约束来进行立体估计。通过寻找局部不一致的标记像素，Gidaris等人\cite{gidaris2016detect}提出了检测、替换和精炼(detect, replace, refine, DRR)框架。此外，视差也可以通过结合中高级的视觉任务来实现正则化。比如，视差估计可以和语义分割同步完成\cite{yamaguchi2014}；Guney和Geiger提出了Displets\cite{guney2015displets}，利用目标识别和语义分割来寻找立体匹配点。

端到端的视差学习：通过仔细地设计和监督训练神经网络模型，可以直接从输入的立体图像对中学习匹配规律，从而获得比较精细的视差结果。Mayer\cite{mayer2016large}等人提出了一种新颖的网络模型DispNet，使用合成的立体图像对训练端到端的卷积神经网络。GC-Net\cite{kendall2017end}在神经网络中显式地学习特征提取、代价集(cost volume)和正则化函数。级联残差学习(CRL)\cite{pang2017cascade}是一个级联的CNN架构，采用了由粗到细和残差学习原理。



%------------------------------------------------------------------------------------
\section{本文主要内容及结构安排}
%\subsection{本论文的主要内容}
%\subsection{本论文的结构安排}

本文的主要研究内容是基于立体视觉的目标检测与定位技术。在构建包含图像获取、摄像机标定、立体匹配和三维重建的双目立体视觉算法框架的基础上，重点研究实时的目标检测和立体匹配算法。融合检测框与匹配所得到的视差图并结合坐标变换实现对目标的定位。搭建了旋翼无人机目标检测定位实验平台以验证本文算法的有效性。

本文主要包含六章，具体章节安排如下：

第一章，绪论。介绍了旋翼无人机目标检测和定位的研究背景与研究意义，对目标检测以及双目立体视觉的关键环节立体匹配的研究概况进行了详细的分析与归类，最后给出本文的结构安排。

第二章，双目立体视觉理论基础。介绍摄像机成像过程中的几个坐标系及其转换关系，建立摄像机的线性数学模型；之后对透镜畸变因素进行建模，并建立摄像机的非线性模型。另外介绍了双目立体视觉的基本原理，包括基于平行光轴视觉模型的三角测量原理、对极几何理论、Bouguet立体校正算法等，总结了使用双目立体视觉求解深度信息的步骤。最后使用张正友摄像机标定法对ZED双目立体相机进行了标定。

第三章，目标检测。由于使用了基于卷积神经网络的算法，因此首先介绍了卷积神经网络的基础知识，包括卷积运算的三个基本思想、卷积神经网络的结构及网络训练中的相关算法。之后引入了YOLO目标检测模型，分析了算法的策略与过程，对模型中损失函数和网络结构做了一些调整改进，在PASCAL VOC数据集上完成模型训练，并给出了测试结果。

第四章，立体匹配。首先梳理了传统立体匹配算法，引出端到端的立体匹配模型DispNet。介绍了DispNet及其变种结构DispNetC的网络架构，搭建了DispNetC网络并在FlyingThings3D和KITTI数据集上分别进行了训练和参数调节，给出了测试结果并与SGM、SPS-St等算法进行了对比。最后讨论了训练集大小对匹配精度的影响。

第五章，旋翼无人机目标检测定位系统的实现。介绍了所搭建实验平台的系统组成，提出了融合目标检测与立体匹配结果的策略。使用GrabCut算法获取目标轮廓并确定目标中心，利用三角测量原理实现摄像机坐标系下的目标定位。再通过坐标变换，完成机体系和导航系下的目标定位。最后给出了实验结果和误差分析。

第六章，总结与展望。总结本文完成的各项工作内容，并分析了工作中的不足之处，列出了未来在算法及应用方面可以开展的几项工作。










