% 第一章 综述

\chapter{综述}

\section{研究背景及意义}

提一下目标定位一般有什么方法，然后引到双目立体视觉。
% 目标定位的研究概况？

%------------------------------------------------------------------------------------
\section{目标检测的研究概况}

\section{立体匹配的研究概况}
% 研究现状，研究目标，研究内容

% ref: GC-Net ch2.
使用立体图像对来计算深度信息的研究已经进行了很多年\cite{Barnard:1982:CS:356893.356896}，而立体匹配是双目立体视觉中最重要的部分。Scharstein和Szeliski于2002年发表的一篇综述论文\cite{Scharstein2002}对立体匹配算法进行了分类，将立体匹配分为四个步骤：匹配代价计算(matching cost computation)、代价支持聚合(cost support aggregation)、视差计算和优化(disparity computation and optimization)和视差精炼(disparity refinement)。大部分立体匹配算法都可以归类为这四个步骤的子集。

Scharstein的综述还介绍了Middlebury的第一个数据集和相关的评价指标，并提供了使用结构光测量方法获得的数据集的测量真值(groundtruth)。KITTI数据集\cite{Geiger2012,Menze_2015_CVPR}是一个比Middlebury更大的数据集，其图像是在一辆行驶中的汽车上采集的，真实数据通过激光雷达获得。这些数据集推动了立体匹配算法的发展。
近年来随着深度学习的流行，出现了很多基于卷积神经网络的立体匹配方法。在此我们将不使用深度学习模型的方法归为传统方法，和基于深度学习的方法分别进行介绍。

\subsection{传统立体匹配方法}
% ref: SGM paper ch1.
传统立体匹配方法大致可分为局部方法和全局方法两类。局部方法至少包含匹配代价计算、代价聚合和视差计算三个部分。匹配代价是一种用来衡量潜在匹配区域内像素差异性的手段。常见的匹配代价包括绝对差值、平方差值、截断差值和对采样不敏感的差值\cite{Birchfield1999}等。这些代价对于光照度差异比较敏感，可以采用基于图像梯度的匹配代价进行改善\cite{SGM_3}。为了处理图像间复杂的光照度关系，互信息被引入了计算机视觉领域\cite{Viola1997}，并应用于立体匹配中\cite{SGM_6}。匹配代价聚合将一定范围内的匹配代价联系起来，通常仅仅是在某个固定尺寸的窗口内对所有的匹配代价进行求和\cite{Hirschmüller2002}。也有一些方法根据颜色相似度和距离中心的距离对窗口内各个像素进行加权\cite{SGM_10}。另外一种方式是根据基于相同亮度或颜色进行分割得到的结果来选择代价聚合的区域\cite{Zitnick:2004}。视差计算是通过选择最低匹配代价的视差完成的\cite{Hirschmüller2002}，即“赢者通吃”(Winner Takes All)。局部方法计算量小，算法效率高，但对于低纹理、遮挡和视差不连续的区域匹配效果较差。

全局匹配方法一般会跳过代价聚集的步骤，定义一个包含数据项和平滑项的能量函数，将匹配转化为最小化能量函数的优化问题。平滑项的加入有助于获得分段光滑的视差。有些算法还会额外加入惩罚遮挡\cite{SGM_13}、强制左右图一致性\cite{Zitnick:2004}的数据项。最小化能量函数的策略有很多，包括图割(Graph Cuts)\cite{SGM_13}，置信传播(Belief Propagation)\cite{SGM_3}，动态规划\cite{VanMeerbergen2002}等。\cite{MRF}和\cite{CRF}分别使用数据集的真实深度图来训练马尔科夫随机场(MRF)和条件随机场(CRF)模型。

全局匹配算法的优点是匹配准确度较高，但其计算量很大，相应的参数设置也比较复杂。半全局匹配(SGM)\cite{Hirschmuller08}是一种对全局算法的有效近似，通过多个方向上的动态规划降低了计算复杂度，既能获得媲美全局算法的的匹配效果，又能保证较高的效率。

\subsection{基于深度学习的立体匹配方法}
% ref: CRL paper, ch2; SsSMNet paper ch2.
传统立体匹配方法对于匹配无纹理区域、反射平面、重复图案、细微结构等表现不佳。很多算法通过池化、基于梯度的正则化\cite{geiger2010efficient, hirschmuller2005accurate}来解决这些问题，但通常需要在平滑表面和检测细节方面进行折中。而深度学习模型已经在物体分类\cite{krizhevsky2012imagenet}、检测\cite{girshick2014rich}和语义分割\cite{badrinarayanan2015segnet}等方面取得了巨大成功，显示出了深度卷积神经网络在理解语义方面的有效性。事实上，近年来深度卷积神经网络也已被成功应用于立体匹配，并大大推动了该领域的发展。基于CNN的匹配方法大致可以分为三类：匹配代价学习、
正则学习(regularity learning)和端到端(End-to-end)的视差学习。

匹配代价学习：使用卷积神经网络获得的图像特征取代人工设计的匹配代价指标。Han等人\cite{Han_2015_CVPR}提出了MatchNet，该模型从成对的图像块中提取特征，然后用一个决策模块来衡量相似度。Zbontar等人\cite{zbontar2016stereo}设计了MC-CNN模型，训练了一个用于匹配的二元分类器。Luo等人\cite{luo2016efficient}提出了Content-CNN用来学习所有视差值的概率分布，这种策略不需要考虑训练样本数量的不平衡。尽管此类数据驱动的相似度指标表现优于传统的手工指标，后处理对于获得理想的匹配结果仍然是必要的。

正则学习：基于视差图通常是分段平滑的事实，一些模型在学习过程中强制加入了平滑约束。Menze等人\cite{Menze_2015_CVPR}应用基于纹理和边缘信息的自适应平滑约束来进行立体估计。通过寻找局部不一致的标记像素，Gidaris等人\cite{gidaris2016detect}提出了检测、替换和精炼(detect, replace, refine, DRR)框架。此外，视差也可以通过结合中高级的视觉任务来实现正则化。比如，视差估计可以和语义分割同步完成\cite{yamaguchi2014}；Guney和Geiger提出了Displets\cite{guney2015displets}，利用目标识别和语义分割来寻找立体匹配点。

端到端的视差学习：通过仔细地设计和监督训练神经网络模型，可以直接从输入的立体图像对中学习匹配规律，从而获得比较精细的视差结果。Mayer\cite{mayer2016large}等人提出了一种新颖的网络模型DispNet，使用合成的立体图像对训练端到端的卷积神经网络。GC-Net\cite{kendall2017end}在神经网络中显式地学习特征提取、代价集(cost volume)和正则化函数。级联残差学习(CRL)\cite{pang2017cascade}是一个级联的CNN架构，采用了由粗到细和残差学习原理。

%------------------------------------------------------------------------------------
\section{本文主要内容及结构安排}
\subsection{本论文的主要内容}

\subsection{本论文的结构安排}












